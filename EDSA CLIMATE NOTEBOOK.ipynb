{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d2b84c",
   "metadata": {},
   "source": [
    "# CLASSIFICATION Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**TEAM CBB3**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Predict Overview: EDSA - Climate Change Belief Analysis 2022\n",
    "\n",
    "Many companies are built around lessening one’s environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "With this context, EDSA is challenging you during the Classification Sprint with the task of creating a Machine Learning model that is able to classify whether or not a person believes in climate change, based on their novel tweet data.\n",
    "\n",
    "Providing an accurate and robust solution to this task gives companies access to a broad base of consumer sentiment, spanning multiple demographic and geographic categories - thus increasing their insights and informing future marketing strategies.\n",
    "\n",
    "### Data overview\n",
    "Data The collection of this data was funded by a Canada Foundation for Innovation JELF Grant to Chris Bauch, University of Waterloo. The dataset aggregates tweets pertaining to climate change collected between Apr 27, 2015 and Feb 21, 2018. In total, 43943 tweets were collected. Each tweet is labelled as one of the following classes:\n",
    "\n",
    "Class Description\n",
    "* 2 News: the tweet links to factual news about climate change\n",
    "* 1 Pro: the tweet supports the belief of man-made climate change\n",
    "* 0 Neutral: the tweet neither supports nor refutes the belief of man-made climate change\n",
    "* -1 Anti: the tweet does not believe in man-made climate change\n",
    "\n",
    "Variable definitions\n",
    "- sentiment: Sentiment of tweet\n",
    "- message: Tweet body\n",
    "- tweetid: Twitter unique id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12f436",
   "metadata": {},
   "source": [
    "# Team Supervisor\n",
    "- Chris Barnett\n",
    "\n",
    "# TEAM CBB3 MEMBERS\n",
    "- 1. Elelwani Tshikovhi (Team Leader);\n",
    "- 2. Katlego Maponya (Team coordinator) ;\n",
    "- 3. Musa Mashaba ;\n",
    "- 4. Zwothandwa Kunene ;\n",
    "- 5. Sinethemba Nongqoto;\n",
    "- 6. Desree Maleka\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ded8e9",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "<a href=#one>1. Importing Packages</a>\n",
    "\n",
    "<a href=#two>2. Loading Data</a>\n",
    "\n",
    "<a href=#three>3. Data Engineering</a>\n",
    "\n",
    "<a href=#four>4. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#five>5. Modeling</a>\n",
    "\n",
    "<a href=#six>6. Model Performance</a>\n",
    "\n",
    "<a href=#seven>7. Model Explanations</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438dc4e6",
   "metadata": {},
   "source": [
    "<a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "|  |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78070faf",
   "metadata": {},
   "source": [
    "# Import all the  **libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3812352",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\27815\\Desktop\\github\\GitHub Workshop.pdf\\predict-notebook\\EDSA CLIMATE NOTEBOOK.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/27815/Desktop/github/GitHub%20Workshop.pdf/predict-notebook/EDSA%20CLIMATE%20NOTEBOOK.ipynb#ch0000005?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/27815/Desktop/github/GitHub%20Workshop.pdf/predict-notebook/EDSA%20CLIMATE%20NOTEBOOK.ipynb#ch0000005?line=3'>4</a>\u001b[0m \u001b[39m# Visualisations\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/27815/Desktop/github/GitHub%20Workshop.pdf/predict-notebook/EDSA%20CLIMATE%20NOTEBOOK.ipynb#ch0000005?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/27815/Desktop/github/GitHub%20Workshop.pdf/predict-notebook/EDSA%20CLIMATE%20NOTEBOOK.ipynb#ch0000005?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/27815/Desktop/github/GitHub%20Workshop.pdf/predict-notebook/EDSA%20CLIMATE%20NOTEBOOK.ipynb#ch0000005?line=6'>7</a>\u001b[0m \u001b[39m# Preprocessing\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Data analysis and wrangling libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualisations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Preprocessing\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Modelling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Metrics for Model Evaluation\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Downloads\n",
    "#nltk.download('all')\n",
    "#nltk.download('stopwords')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa75f48",
   "metadata": {},
   "source": [
    "### Download NLTK Corpora\n",
    "Some of the `nltk` text processing methods introduced in this train involve a lookup operation. For example, to find all [stopwords](https://www.geeksforgeeks.org/removing-stop-words-nltk-python/) in a given string of text, we require a list of all possible stopwords in the English language to use for the lookup. Such a list is refered to as a [corpus](https://en.wikipedia.org/wiki/Text_corpus). Therefore, we need to first download the corpora we're going use, otherwise we may get a lookup error! Watch out specifically for the `tokenize` and `stopwords` sections. Not to worry, as we can easily avoid these errors by downloading the [corpora](http://www.nltk.org/nltk_data/) using the `nltk` downloader tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc51f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\27815\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\27815\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(['punkt','stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5d754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stopwords_list = stopwords.words('english')\n",
    "print(stopwords_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20bef0",
   "metadata": {},
   "source": [
    "pip intall comet version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aabdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comet_ml in c:\\users\\27815\\anaconda3\\lib\\site-packages (3.31.3)\n",
      "Requirement already satisfied: everett[ini]>=1.0.1 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (3.0.0)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (2.10.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (3.2.0)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (7.352.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (0.9.1)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (0.20.43)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (3.0.2)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (2.26.0)\n",
      "Requirement already satisfied: six in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (1.16.0)\n",
      "Requirement already satisfied: websocket-client>=0.55.0 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (1.3.2)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from comet_ml) (1.12.1)\n",
      "Requirement already satisfied: urllib3>=1.24.1 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from dulwich!=0.20.33,>=0.20.6->comet_ml) (1.26.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\27815\\anaconda3\\lib\\site-packages (from dulwich!=0.20.33,>=0.20.6->comet_ml) (2021.10.8)\n",
      "Requirement already satisfied: configobj in c:\\users\\27815\\anaconda3\\lib\\site-packages (from everett[ini]>=1.0.1->comet_ml) (5.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\27815\\anaconda3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (58.0.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.18.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\27815\\anaconda3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8cea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: sklearn. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/elelwani-tshikovhi/team-cbb-3-classification/8100969bb10941a995f2015636c1b9d8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import comet_ml at the top \n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"rI7gAvhuv8lNvQcjSox3TjwIF\",\n",
    "    project_name=\"team-cbb-3-classification\",\n",
    "    workspace=\"elelwani-tshikovhi\",\n",
    ")\n",
    "\n",
    "# Run your code and go to /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd42284",
   "metadata": {},
   "source": [
    "*   [Trello Link](https://trello.com/b/2KvEPRJi/advanced-classificatin-team-cbb3-week-1)\n",
    "*   [Link to comet](https://www.comet.ml/elelwani-tshikovhi/team-cbb-3-classification/view/new/panels)\n",
    "*   [Link to Github](https://github.com/TEAMCBB3Classificationpredict)\n",
    "*   [Link to streamlit]( http://34.244.129.101:5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed07070",
   "metadata": {},
   "source": [
    "<a id=\"two\"></a>\n",
    "## 2. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef35b6",
   "metadata": {},
   "source": [
    "The training and testing data, trains_set and test_set respectively are loaded as Pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "238720ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/TEAMCBB3Classificationpredict/datasets/main/train.csv')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/TEAMCBB3Classificationpredict/datasets/main/test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b902548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Worth a read whether you do or don't believe i...</td>\n",
       "      <td>425577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @thenation: Mike Pence doesn’t believe in g...</td>\n",
       "      <td>294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @makeandmendlife: Six big things we can ALL...</td>\n",
       "      <td>992717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>@AceofSpadesHQ My 8yo nephew is inconsolable. ...</td>\n",
       "      <td>664510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @paigetweedy: no offense… but like… how do ...</td>\n",
       "      <td>260471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954\n",
       "5          1  Worth a read whether you do or don't believe i...   425577\n",
       "6          1  RT @thenation: Mike Pence doesn’t believe in g...   294933\n",
       "7          1  RT @makeandmendlife: Six big things we can ALL...   992717\n",
       "8          1  @AceofSpadesHQ My 8yo nephew is inconsolable. ...   664510\n",
       "9          1  RT @paigetweedy: no offense… but like… how do ...   260471"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298ceb1",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 3. Data cleaning\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data Cleaning ⚡ |\n",
    "| :--------------------------- |\n",
    "|  clean the dataset, and possibly create new features -using Natural language process . |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f89ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97706177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b588ce7c",
   "metadata": {},
   "source": [
    "<a id=\"three\"></a>\n",
    "## 4. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "|This phase is important. This will help to understand patterns in the data, pinpoint any outliers and indicate relationships between variables uusing  descriptive statistics and data visualisations\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04ce8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e6d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86a6be65",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, create one or more regression models that are able to accurately predict the Sentiment. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0198409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92345e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53fb7df1",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5592c0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66154507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddc1c80f",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3513b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1aea6481d516a43a63e7597583eb5c23bd9d781aa77adbd6919170e7345ad19b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
